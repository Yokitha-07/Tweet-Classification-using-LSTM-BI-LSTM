{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "chFxLC6rxIuW"
      },
      "outputs": [],
      "source": [
        "#Import all the libraries needed\n",
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview dataset"
      ],
      "metadata": {
        "id": "GDa_MsDyx_Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dSRVxC5JxIuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a260695-0eaf-42e8-eeae-fe2738e7a077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "          tweet_id  label                                              tweet\n",
            "0     6.430000e+17      0  user_mention all i can tell you is i have had ...\n",
            "1     6.440000e+17      0  my doctor told me stop he gave me sum pop i mi...\n",
            "2     8.150000e+17      1  i take tylenol and i wake up in the middle of ...\n",
            "3     6.820000e+17      0  i got xans in an advil bottle i dont take them...\n",
            "4     6.440000e+17      1  mom says i need to stop eating so much bc ive ...\n",
            "...            ...    ...                                                ...\n",
            "9986  6.480000e+17      1                          that vicodin messed me up\n",
            "9987  5.710000e+17      0                  user_mention get some tylenol lol\n",
            "9988  6.470000e+17      0                          like a walking tamiflu ad\n",
            "9989  6.990000e+17      0                         klay and steph on steroids\n",
            "9990  8.230000e+17      0                    horrible pops another xanax url\n",
            "\n",
            "[9991 rows x 3 columns]\n",
            "          tweet_id  label                                              tweet\n",
            "0     6.411550e+17      0  when you try to run away from the iv needle so...\n",
            "1     6.425520e+17      1  i just knew i took an ambien for sleep too ear...\n",
            "2     6.410410e+17      1  i mean i get that my celexa is the reason behi...\n",
            "3     7.476620e+17      0  if you call me dumb or her dumb one more time ...\n",
            "4     6.406830e+17      0  i do not want to go to the grocery store but i...\n",
            "...            ...    ...                                                ...\n",
            "3326  6.392340e+17      0                         fina take this xanax knock\n",
            "3327  6.398700e+17      0                user_mention yr on citalopram right\n",
            "3328  6.433340e+17      0                   user_mention yeah im going norco\n",
            "3329  5.588580e+17      0                   user_mention tylenol w codin lol\n",
            "3330  7.131560e+17      0                thats determination on steroids url\n",
            "\n",
            "[3331 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_train = pathlib.Path('/content/drive/My Drive/phm_train.csv')\n",
        "data_test = pathlib.Path('/content/drive/My Drive/phm_test.csv')\n",
        "dtrain = pd.read_csv(data_train)\n",
        "dtest = pd.read_csv(data_test)\n",
        "print(dtrain)\n",
        "print(dtest)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring the english stop words"
      ],
      "metadata": {
        "id": "Uh5243vMyKhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nzux8uRZxIuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02f0612-7163-48dc-940f-4af81e003f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing and Encoding labels"
      ],
      "metadata": {
        "id": "lA4BqsNlySGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uL16UfD6xIua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3a9a9a-7a36-4ba1-fc8c-f3935bc146b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet\n",
            "0       [user, mention, tell, relapses, cure, hear, do...\n",
            "1       [doctor, told, stop, gave, sum, pop, mix, w, a...\n",
            "2       [take, tylenol, wake, middle, night, put, ice,...\n",
            "3       [got, xans, advil, bottle, dont, take, shits, ...\n",
            "4       [mom, says, need, stop, eating, much, bc, ive,...\n",
            "                              ...                        \n",
            "9986                                    [vicodin, messed]\n",
            "9987                   [user, mention, get, tylenol, lol]\n",
            "9988                         [like, walking, tamiflu, ad]\n",
            "9989                              [klay, steph, steroids]\n",
            "9990                [horrible, pops, another, xanax, url]\n",
            "Name: tweet, Length: 9991, dtype: object \n",
            "\n",
            "label\n",
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "9986    1\n",
            "9987    0\n",
            "9988    0\n",
            "9989    0\n",
            "9990    0\n",
            "Name: label, Length: 9991, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def load_dataset():\n",
        "  x_train = dtrain['tweet']     # tweets/Input\n",
        "  y_train = dtrain['label']    # label/Output\n",
        "\n",
        "\n",
        "    # PRE-PROCESS tweet\n",
        "  x_train = x_train.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "  x_train = x_train.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "  x_train = x_train.apply(lambda tweet: [w for w in tweet.split() if w not in english_stops])  # remove stop words\n",
        "  x_train = x_train.apply(lambda tweet: [w.lower() for w in tweet])   # lower case\n",
        "\n",
        "  return x_train, y_train\n",
        "\n",
        "x_train, y_train = load_dataset()\n",
        "\n",
        "print('tweet')\n",
        "print(x_train, '\\n')\n",
        "print('label')\n",
        "print(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset2():\n",
        "  x_test = dtest['tweet']     # tweets/Input\n",
        "  y_test = dtest['label']   # label/Output\n",
        "\n",
        "  # PRE-PROCESS tweet\n",
        "  x_test = x_test.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "  x_test = x_test.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "  x_test = x_test.apply(lambda tweet: [w for w in tweet.split() if w not in english_stops])  # remove stop words\n",
        "  x_test = x_test.apply(lambda tweet: [w.lower() for w in tweet])   # lower case\n",
        "\n",
        "  return x_test, y_test\n",
        "\n",
        "x_test, y_test = load_dataset2()\n",
        "\n",
        "print('tweet')\n",
        "print(x_test, '\\n')\n",
        "print('label')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n784nSqSQbMT",
        "outputId": "909a0f3a-74ee-48b3-8924-cff415e03113"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet\n",
            "0       [try, run, away, iv, needle, doctor, drug, w, ...\n",
            "1       [knew, took, ambien, sleep, early, im, ready, ...\n",
            "2       [mean, get, celexa, reason, behind, lot, weigh...\n",
            "3       [call, dumb, dumb, one, time, dont, care, many...\n",
            "4       [want, go, grocery, store, cant, pay, anyone, ...\n",
            "                              ...                        \n",
            "3326                           [fina, take, xanax, knock]\n",
            "3327               [user, mention, yr, citalopram, right]\n",
            "3328              [user, mention, yeah, im, going, norco]\n",
            "3329              [user, mention, tylenol, w, codin, lol]\n",
            "3330                [thats, determination, steroids, url]\n",
            "Name: tweet, Length: 3331, dtype: object \n",
            "\n",
            "label\n",
            "0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3326    0\n",
            "3327    0\n",
            "3328    0\n",
            "3329    0\n",
            "3330    0\n",
            "Name: label, Length: 3331, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for getting the maximum tweet length, by calculating the mean of all the tweets length (using numpy.mean)"
      ],
      "metadata": {
        "id": "yaz82yjyykT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B-5QgyYgxIuc"
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    tweet_length = []\n",
        "    for tweet in x_train:\n",
        "        tweet_length.append(len(tweet))\n",
        "\n",
        "    return int(np.ceil(np.mean(tweet_length)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize and Pad/Truncate tweets\n",
        "#post, pad or truncate the words in the back of a sentence\n",
        "#pre, pad or truncate the words in front of a sentence"
      ],
      "metadata": {
        "id": "ASGim_ImyrZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j3dXUq6QxIuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dde0543-19a7-44b7-9312-9fe34ef41d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[    2     1   200 ...   944  3624  1952]\n",
            " [  115   122   147 ...   193    40   322]\n",
            " [    6     3   330 ...   626  1710    29]\n",
            " ...\n",
            " [    7   529  1739 ...     0     0     0]\n",
            " [12658 12659     8 ...     0     0     0]\n",
            " [  645  1436   174 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  98  606  109 ...  193    4  318]\n",
            " [ 585   11   56 ...   16  707   55]\n",
            " [ 327   12 1209 ...  778    5   88]\n",
            " ...\n",
            " [   2    1  126 ...    0    0    0]\n",
            " [   2    1    3 ...    0    0    0]\n",
            " [  59    8    9 ...    0    0    0]] \n",
            "\n",
            "Maximum tweet length:  10\n"
          ]
        }
      ],
      "source": [
        "# ENCODE tweet\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum tweet length: ', max_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_#Build the model_LSTM"
      ],
      "metadata": {
        "id": "EGmkzZzryxRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zKsE4CzxxIuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "0a37bd3a-11e5-4d03-8130-0d1d73f9f2c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m810,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">810,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m909,185\u001b[0m (3.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">909,185</span> (3.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m909,185\u001b[0m (3.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">909,185</span> (3.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 64\n",
        "LSTM_OUT = 128\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.build(input_shape=(None, max_length))\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set hyperparameters\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GaEkDqp0y3s8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "HfXVls9hzBrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ncwxJzJ4xIud"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.keras',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training- LSTM"
      ],
      "metadata": {
        "id": "gY6F99qYRorZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "e_DGv7xXxIud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23349eae-0198-4d33-d7e8-5a28fc677993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9943 - loss: 0.0173\n",
            "Epoch 1: accuracy improved from -inf to 0.99339, saving model to models/LSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9943 - loss: 0.0174\n",
            "Epoch 2/5\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9947 - loss: 0.0176\n",
            "Epoch 2: accuracy improved from 0.99339 to 0.99450, saving model to models/LSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9947 - loss: 0.0176\n",
            "Epoch 3/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9962 - loss: 0.0137\n",
            "Epoch 3: accuracy improved from 0.99450 to 0.99530, saving model to models/LSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9962 - loss: 0.0138\n",
            "Epoch 4/5\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9959 - loss: 0.0128\n",
            "Epoch 4: accuracy did not improve from 0.99530\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9959 - loss: 0.0129\n",
            "Epoch 5/5\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9952 - loss: 0.0164\n",
            "Epoch 5: accuracy did not improve from 0.99530\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9952 - loss: 0.0166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dbbb0ab5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Bi-LSTM model\n",
        "\n",
        "model_bilstm = Sequential()\n",
        "model_bilstm.add(Embedding(total_words, output_dim=128))\n",
        "model_bilstm.add(Bidirectional(LSTM(64)))  # Bi-directional LSTM\n",
        "model_bilstm.add(Dense(1, activation='sigmoid'))\n",
        "model_bilstm.build(input_shape=(None, max_length))\n",
        "\n",
        "print(model_bilstm.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "oC5T_VkKaIy-",
        "outputId": "57b3aa13-0e8d-49c6-d84b-3457ca232933"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,620,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,620,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,719,425\u001b[0m (6.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,719,425</span> (6.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,719,425\u001b[0m (6.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,719,425</span> (6.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set hyperparameters - Bi_LSTM\n",
        "model_bilstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "vzyedSEEa03q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint1 = ModelCheckpoint(\n",
        "    'models/BiLSTM.keras',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ZfMvt0o0a8iC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training- Bi-LSTM"
      ],
      "metadata": {
        "id": "IX4D1PdNbyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qngUVSFZbQtt",
        "outputId": "1934a94f-4b15-4ed0-8512-e58187315f77"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9766 - loss: 0.0781\n",
            "Epoch 1: accuracy improved from -inf to 0.97087, saving model to models/BiLSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.9764 - loss: 0.0784\n",
            "Epoch 2/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9765 - loss: 0.0735\n",
            "Epoch 2: accuracy improved from 0.97087 to 0.97478, saving model to models/BiLSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9764 - loss: 0.0735\n",
            "Epoch 3/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9859 - loss: 0.0548\n",
            "Epoch 3: accuracy improved from 0.97478 to 0.98218, saving model to models/BiLSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9858 - loss: 0.0549\n",
            "Epoch 4/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9880 - loss: 0.0472\n",
            "Epoch 4: accuracy improved from 0.98218 to 0.98619, saving model to models/BiLSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9880 - loss: 0.0472\n",
            "Epoch 5/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9905 - loss: 0.0334\n",
            "Epoch 5: accuracy improved from 0.98619 to 0.98839, saving model to models/BiLSTM.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.9905 - loss: 0.0336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dbbb131910>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing-LSTM"
      ],
      "metadata": {
        "id": "DqUvLFwhzGYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7cIDxgtxxIud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9727cff-2567-473e-d8c3-2218e5900e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Correct Prediction: 2569\n",
            "Wrong Prediction: 762\n",
            "Accuracy: 77.12398679075353\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(x=x_test)\n",
        "y_pred = (pred >= 0.5) * 1\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing- Bi-LSTM"
      ],
      "metadata": {
        "id": "i_5J72uZbhF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VvWhkDfXxIug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7103e029-851d-4649-a7a6-96a84c56e3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Correct Prediction: 2619\n",
            "Wrong Prediction: 712\n",
            "Accuracy: 78.62503752626839\n"
          ]
        }
      ],
      "source": [
        "pred = model_bilstm.predict(x=x_test)\n",
        "y_pred = (pred >= 0.5) * 1\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}